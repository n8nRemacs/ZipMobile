# GreenSpark Parser - FAQ и Документация

## Обзор

Парсер для сбора товаров с сайта [green-spark.ru](https://green-spark.ru/) (оптовый поставщик запчастей для мобильных устройств).

---

## Структура файлов

```
GreenSpark/
├── parser_v3.py        # Основной парсер (v3 - автономный с IP ротацией)
├── fill_articles.py    # Массовое заполнение артикулов через HTML
├── get_cookies.py      # Получение cookies через Playwright
├── stealth_cookies.py  # Альтернативный stealth-режим для cookies
├── telegram_notifier.py # Telegram уведомления
├── config.py           # Конфигурация (URL, пути, задержки)
├── cookies.json        # Cookies для авторизации (генерируется автоматически)
├── data/
│   ├── products.json   # Результат парсинга (JSON)
│   ├── products.xlsx   # Результат парсинга (Excel)
│   ├── categories.json # Маппинг категорий slug → название
│   ├── greenspark_cities.json # Список городов (60 шт)
│   └── errors.json     # Лог ошибок
└── README.md           # Этот файл
```

---

## Архитектура парсера v3

### Ключевые возможности

1. **Полностью автономный** - не требует ручного вмешательства
2. **Единая номенклатура** - все товары в одной таблице по URL (уникальный идентификатор)
3. **Мультигородской парсинг** - парсинг всех 60 городов с разными ценами
4. **IP ротация** - автоматическое переключение между серверами при блокировке
5. **Оптимизированный допарсинг** - артикулы берутся из БД, HTTP только для новых
6. **Инкрементальное сохранение** - каждые 200 товаров в БД
7. **Telegram уведомления** - оповещения о блокировках и прогрессе

### Серверы

| Имя | IP | Расположение |
|-----|-----|--------|
| server-a | 85.198.98.104 | Основной, БД |
| server-b-ip1 | 155.212.221.189 | Резервный |
| server-b-ip2 | 217.114.14.17 | Резервный (тот же хост) |
| server-c | 155.212.221.67 | Резервный |

### Требования к серверам

- `/opt/parsers/GreenSpark/` - директория с парсером
- `xvfb`, `playwright`, `chromium` - для получения cookies
- `httpx[socks]`, `socksio` - для SSH туннелей
- SSH ключи настроены между всеми серверами

### SSH ключи (настроено 2026-01-16)

Все серверы могут подключаться друг к другу по SSH без пароля:
```
server-a ↔ server-b ↔ server-c
```

Это необходимо для:
1. Автоматической ротации IP через SSH туннели
2. Получения cookies на удалённом сервере через xvfb

---

## Архитектура БД (v3.3)

### Единая номенклатура

```sql
-- Все товары в одной таблице (уникальность по URL)
CREATE TABLE greenspark_nomenclature (
    id SERIAL PRIMARY KEY,
    name TEXT NOT NULL,
    product_url TEXT NOT NULL UNIQUE,  -- URL = уникальный идентификатор товара
    article VARCHAR(50),               -- NULL если ещё не допарсен
    category TEXT,
    first_seen_at TIMESTAMP,
    updated_at TIMESTAMP
);

-- Цены по городам
CREATE TABLE greenspark_prices (
    id SERIAL PRIMARY KEY,
    nomenclature_id INT REFERENCES greenspark_nomenclature(id),
    outlet_id INT REFERENCES outlets(id),
    price NUMERIC,
    price_wholesale NUMERIC,
    in_stock BOOLEAN,
    updated_at TIMESTAMP,
    UNIQUE(nomenclature_id, outlet_id)
);

-- Точки продаж (города)
CREATE TABLE outlets (
    id SERIAL PRIMARY KEY,
    code VARCHAR(100) UNIQUE,  -- greenspark-{city_id}
    city VARCHAR(100),
    name VARCHAR(200),
    is_active BOOLEAN
);
```

### Преимущества новой архитектуры

1. **URL как ID** - один товар = один URL, независимо от артикула
2. **Все товары сохраняются** - даже без артикула (артикул допарсивается позже)
3. **Оптимизированный допарсинг** - артикулы кэшируются между городами
4. **Быстрый мониторинг** - после первого прохода только обновление цен

### Подключение к БД

```
Host: 85.198.98.104
Port: 5433
DB: db_greenspark
User: postgres
```

---

## Автоматическая работа

### Парсер работает полностью автономно:

1. **Запуск** → автоматически получает cookies через xvfb + non-headless браузер
2. **Этап 1** → парсинг категорий, сохранение каждые 200 товаров в `greenspark_nomenclature`
3. **Этап 2** → допарсинг артикулов:
   - Сначала проверяет БД (артикул мог быть найден для другого города)
   - HTTP запрос только если артикула нет в БД
4. **Блокировка** → Telegram, ожидание 50 мин, переключение сервера
5. **Завершение** → итоговая статистика в Telegram

**Ручное вмешательство НЕ требуется!**

---

## Запуск парсера

### Параметры parser_v3.py

```bash
--server NAME       # Имя текущего сервера (ОБЯЗАТЕЛЬНО)
--all-cities        # Парсить все города
--city NAME         # Парсить конкретный город по имени
--skip-parsed       # Пропускать города с данными за сегодня
--category CAT      # Стартовая категория
--no-reparse        # Без допарсинга артикулов
--no-db             # Без сохранения в БД
```

### Примеры запуска

```bash
# SSH на сервер
ssh root@85.198.98.104
cd /opt/parsers/GreenSpark

# Парсинг всех городов
nohup python3 parser_v3.py --server server-a --all-cities > parser.log 2>&1 &

# Парсинг всех городов, пропуская спарсенные сегодня
nohup python3 parser_v3.py --server server-a --all-cities --skip-parsed > parser.log 2>&1 &

# Парсинг конкретного города
nohup python3 parser_v3.py --server server-a --city Москва > parser.log 2>&1 &

# Мониторинг
tail -f parser.log
```

---

## Оптимизация допарсинга

### Как это работает

При допарсинге артикулов парсер сначала проверяет `greenspark_nomenclature`:

```
Город 1: 2000 товаров без артикулов
  → 2000 HTTP запросов
  → Найдено 1500 артикулов → сохранены в БД

Город 2: 2000 товаров без артикулов
  → Проверка БД: 1500 уже есть!
  → Только 500 HTTP запросов (для новых)

Город 60: почти всё из БД
  → Единичные HTTP запросы
```

### Статистика в логах

```
Допарсинг: найдено 1500 артикулов из 2000
  - Из БД (другие города): 1200
  - Из HTTP запросов: 300
```

---

## Блокировки и разблокировка

### Типы блокировок

| Тип | HTTP код | Описание | Время разблокировки |
|-----|----------|----------|---------------------|
| Жёсткий | 403 | Полный бан IP | ~45-50 минут |
| Мягкий | 200 + HTML | Требует свежие cookies | Мгновенно с новыми cookies |

### Автоматическая обработка

1. Парсер детектит блокировку (HTML вместо JSON или 403)
2. Отправляет Telegram уведомление
3. Ждёт 50 минут (время разбана)
4. Переключается на другой сервер
5. Получает свежие cookies через xvfb
6. Продолжает парсинг

---

## Cookies и Авторизация

### ВАЖНО: Детекция headless браузера

**Сайт green-spark.ru определяет headless браузеры!**

Парсер автоматически использует:
- **Xvfb** (X Virtual Framebuffer) - виртуальный дисплей
- **headless=False** - "видимый" браузер
- **Stealth патчи** - обход детекции автоматизации

### Ручное получение cookies (если нужно)

```bash
cd /opt/parsers/GreenSpark
xvfb-run --auto-servernum python3 stealth_cookies.py
```

---

## Telegram уведомления

### Настройка

```bash
export TELEGRAM_BOT_TOKEN="..."
export TELEGRAM_CHAT_ID="..."
```

### События

- Старт парсинга
- Блокировка IP (с указанием сервера и города)
- Смена сервера
- Завершение города
- Завершение всего парсинга
- Критические ошибки

---

## Проблемы и решения

### 1. API возвращает HTML вместо JSON

**Причина:** Cookies от headless браузера или устаревшие
**Решение:** Парсер автоматически получит новые через xvfb

### 2. IP заблокирован (403)

**Причина:** Слишком много запросов
**Решение:** Парсер ждёт 50 мин и переключает сервер

### 3. Парсер зависает

**Причина:** Сетевой таймаут
**Решение:**
- Timeout 30 сек на каждый запрос
- Unbuffered stdout для немедленного вывода логов
- Проверить: `ps aux | grep parser_v3`

### 4. Товары без артикулов

**Причина:** Артикул не в URL картинки
**Решение:** Допарсинг через HTML страницу товара (API не возвращает артикул!)

**Важно:** JSON API не содержит поле артикула. Артикул парсится только из HTML страницы.

---

## Скрипт fill_articles.py

Отдельный скрипт для массового заполнения артикулов в `greenspark_nomenclature`.

### Запуск

```bash
cd /opt/parsers/GreenSpark
python fill_articles.py
```

### Как работает

1. Получает cookies через `get_cookies.py` (если нет `cookies.json`)
2. Выбирает товары с пустыми артикулами из БД
3. Для каждого товара парсит HTML страницу и извлекает артикул
4. Сохраняет артикул в БД

### Форматы артикулов

| Формат | Пример | Regex |
|--------|--------|-------|
| Буквенный префикс | GS-00001234, ИП-00013251 | `[А-ЯA-Z]{2,3}-\d+` |
| Числовой | 00000000656 | `\d{8,}` |

### Когда использовать

- После первого парсинга всех городов (много товаров без артикулов)
- Если допарсинг в parser_v3.py прерывается из-за блокировки
- Для разового заполнения всех пустых артикулов

---

## История изменений

### v3.5 (2026-01-16)
- **SSH ключи между серверами** - автоматическая ротация IP без пароля
- **Полная автономность** - переключение между server-a, server-b, server-c
- **Статистика артикулов** - 96.3% товаров с артикулами (10,739/11,155)

### v3.4 (2026-01-16)
- **fill_articles.py** - отдельный скрипт для массового заполнения артикулов
- **HTML парсинг артикулов** - API не возвращает артикул, только HTML
- **Форматы артикулов** - поддержка GS-XXXXX и числовых (00000000656)
- **Исправлен lookup** - поиск по URL вместо name+url

### v3.3 (2026-01-15)
- **Единая номенклатура** `greenspark_nomenclature` - все товары по URL
- **UNIQUE(product_url)** вместо UNIQUE(name, product_url)
- **Оптимизация допарсинга** - артикулы берутся из БД между городами
- **greenspark_prices** - отдельная таблица цен для новой архитектуры
- **Время бана 50 минут** (было 20) - реальный разбан ~45 мин

### v3.2 (2026-01-15)
- Параметр `--city` для парсинга конкретного города
- Инкрементальное сохранение при допарсинге артикулов
- Исправлена автономная работа без ручного вмешательства

### v3.1 (2026-01-15)
- Инкрементальное сохранение (каждые 200 товаров)
- Telegram уведомления при блокировке
- Unbuffered stdout для nohup логов
- Добавлен server-c (155.212.221.67)

### v3.0 (2026-01-14)
- IP ротация между серверами
- Автоматическое получение cookies через Xvfb
- Мультигородской парсинг
- Skip parsed cities

### v1-v2 (ранее)
- Базовый парсинг
- Допарсинг артикулов
- Сохранение в JSON/Excel

---

## Установка на новый сервер

```bash
# Создать директорию
mkdir -p /opt/parsers/GreenSpark/data

# Установить зависимости
apt-get update && apt-get install -y xvfb
pip install httpx openpyxl playwright playwright-stealth psycopg2-binary
playwright install chromium --with-deps

# Скопировать файлы парсера
scp parser_v3.py config.py stealth_cookies.py telegram_notifier.py root@SERVER:/opt/parsers/GreenSpark/
scp data/greenspark_cities.json root@SERVER:/opt/parsers/GreenSpark/data/

# Добавить сервер в ENDPOINTS в parser_v3.py
```

---

## Мониторинг

```bash
# Статус процесса
ps aux | grep parser_v3

# Логи в реальном времени
tail -f /opt/parsers/GreenSpark/parser.log

# Количество сохранений
grep -c 'Сохранено' /opt/parsers/GreenSpark/parser.log

# Статистика БД
ssh root@85.198.98.104 "python3 -c \"
import psycopg2
conn = psycopg2.connect(host='85.198.98.104', port=5433, dbname='db_greenspark',
    user='postgres', password='Mi31415926pSss!', sslmode='require')
cur = conn.cursor()
cur.execute('SELECT COUNT(*) FROM greenspark_nomenclature')
print(f'Товаров: {cur.fetchone()[0]}')
cur.execute('SELECT COUNT(*) FROM greenspark_nomenclature WHERE article IS NOT NULL')
print(f'С артикулами: {cur.fetchone()[0]}')
cur.execute('SELECT COUNT(*) FROM greenspark_prices')
print(f'Цен: {cur.fetchone()[0]}')
\""
```
