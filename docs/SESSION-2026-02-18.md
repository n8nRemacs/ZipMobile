# Отчёт о сессии 2026-02-18
Обновлено: 2026-02-18 22:30 (GMT+4)

---

## Выполненная работа

### 1. pg_dump: Cloud → Homelab (полная миграция)

Выполнен полный дамп production БД из Supabase Cloud в локальную Homelab PostgreSQL.

| Параметр | Значение |
|----------|----------|
| Размер дампа | 1.5 GB |
| Таблиц | **79** |
| Функций | **21** |
| Время | ~5 мин |

**Проблемы и решения:**
- `pg_dump` через CLI не работал (libpq v17 auth конфликт с Supabase pooler)
- Решение: connection string с URL-encoded паролем (`%21` вместо `!`)
- Перед импортом дропнули все 31 существующих таблиц на Homelab

### 2. Тестирование всех 10 парсеров на Homelab

Все парсеры запущены на локальной БД (Homelab). Результаты:

| # | Парсер | Nomenclature | Prices | Статус |
|---|--------|-------------|--------|--------|
| 1 | TagGSM | 22,838 | 2,009,744 | OK |
| 2 | Liberti | 16,927 | 231,794 | OK |
| 3 | Profi | 13,583 | 259,954 | OK |
| 4 | Moba | 13,083 | 13,083 | OK |
| 5 | MemsTech | 11,844 | 16,893 | OK |
| 6 | 05GSM | 3,509 | 3,509 | OK |
| 7 | Signal23 | 3,133 | 3,133 | OK |
| 8 | Orizhka | 2,607 | 2,607 | OK |
| 9 | NAFFAS | 1,276 | 1,275 | OK |
| 10 | LCD-Stock | 1,195 | 5,975 | OK |
| | **ИТОГО** | **~90,000** | **~2,548,000** | **10/10** |

### 3. Исправления парсеров

| Парсер | Проблема | Исправление |
|--------|----------|------------|
| 05GSM | `gsm05_nomenclature` нет в TABLE_MAPPING | Добавлен маппинг в db_wrapper.py |
| NAFFAS | Голые имена таблиц (`staging`, `nomenclature`, `price_history`) | Заменены на `moysklad_naffas_*` |
| LCD-Stock | `lcdstock_nomenclature_v2` не существует | Убран суффикс `_v2` в парсере и маппинге |
| Signal23 | `barcode = None.strip()` crash | Исправлено на `(p.get("barcode") or "").strip()` |
| TagGSM | `SupabaseCursor` не имеет `batch_insert` | Добавлены `batch_insert()` и `set_timeout()` в db_wrapper.py |

### 4. Скрипты синхронизации

| Скрипт | Направление | Описание |
|--------|------------|----------|
| `sync_from_cloud.py` | Cloud → Homelab | Инфраструктура: shops, outlets, cities, timezones, countries |
| `sync_to_cloud.py` | Homelab → Cloud | Финальные данные: nomenclature, prices, dicts (не запускался) |

### 5. Документация

- `DATABASE_ARCHITECTURE.md` — полностью переписан (v8.0): двухуровневая архитектура, актуальные данные

---

## TODO: Следующая сессия — Стандартизация GreenSpark

### Проблема

GreenSpark — единственный парсер, который **НЕ работает** на Homelab. Данные = 0 строк.
Причина: парсер `parser_v3.py` использует собственное подключение к старому серверу.

### Текущее состояние GreenSpark

| Файл | Подключение к БД | Статус |
|------|-------------------|--------|
| `parser_v3.py` | Своя `get_db()` → `85.198.98.104:5433/db_greenspark` | **СЛОМАН** — старый сервер не существует |
| `parser.py` | `db_wrapper.get_db()` → Homelab | OK, но использует staging flow |
| `coordinator.py` | Своя `get_db()` → `85.198.98.104:5433/db_greenspark` | **СЛОМАН** |

**Данные в Homelab БД:**
```
greenspark_nomenclature: 0 строк (пусто!)
greenspark_prices:       0 строк
greenspark_staging:      0 строк
greenspark_parse_log:    0 строк
```

**Схема таблиц** — идентична другим парсерам (UUID id, article UNIQUE, те же колонки). Проблема только в коде парсера.

### Что нужно сделать

#### 1. Адаптировать parser_v3.py к общему стандарту

```
БЫЛО:                                    НАДО:
─────                                    ─────
DB_HOST = "85.198.98.104"                from db_wrapper import get_db
DB_PORT = 5433
DB_NAME = "db_greenspark"                conn = get_db()  # → localhost:5433/postgres
DB_USER = "postgres"

def get_db():                            # Удалить свою get_db()
    return psycopg2.connect(
        host=DB_HOST, port=DB_PORT,
        dbname=DB_NAME, user=DB_USER)
```

**Ключевые изменения:**
- Заменить собственную `get_db()` на `from db_wrapper import get_db`
- Убрать все `DB_HOST`, `DB_PORT`, `DB_NAME`, `DB_USER` константы
- Убедиться что все SQL используют `greenspark_*` префиксы (не голые имена)
- Обновить `sys.path.insert` для импорта db_wrapper

#### 2. Адаптировать coordinator.py

Аналогично — заменить собственное подключение на `db_wrapper.get_db()`.

#### 3. Решить какой парсер основной

| Вариант | parser_v3.py | parser.py |
|---------|-------------|-----------|
| Подключение | Сломано (старый сервер) | OK (db_wrapper) |
| Фичи | IP rotation, cookies, Telegram, coordinator | Staging flow, проще |
| Сохранение | Direct UPSERT (быстрее) | Staging → process (двухэтапный) |
| Города | 60 городов через coordinator | Одиночный город |
| **Рекомендация** | **Основной** (после адаптации) | Deprecated |

#### 4. Очистить db_wrapper.py

Удалить маппинги для несуществующих таблиц:
```python
# Эти таблицы НЕ существуют в Homelab — удалить из TABLE_MAPPING:
"parser_progress": "greenspark_parser_progress",     # нет в БД
"parser_queue": "greenspark_parser_queue",            # нет в БД
"parser_request_log": "greenspark_parser_request_log",# нет в БД
"parser_servers": "greenspark_parser_servers",         # нет в БД
"product_lookup": "greenspark_product_lookup",         # нет в БД
"shop_cookies": "greenspark_shop_cookies",             # нет в БД
"shop_parser_configs": "greenspark_shop_parser_configs",# нет в БД
```

#### 5. Запустить парсер и проверить данные

```bash
# На Homelab:
cd /mnt/projects/repos/ZipMobile/SHOPS/GreenSpark
python3 parser_v3.py --city 290112  # Москва — тест одного города
# Проверить: greenspark_nomenclature и greenspark_prices не пусты
```

#### 6. (Опционально) Нужны ли координационные таблицы?

Если будем использовать coordinator.py для параллельного парсинга 60 городов:
```sql
-- Создать на Homelab:
CREATE TABLE greenspark_parser_progress (...);
CREATE TABLE greenspark_parser_queue (...);
CREATE TABLE greenspark_parser_servers (...);
```
Миграция: `SHOPS/GreenSpark/migrations/001_parser_coordination.sql`

### Порядок выполнения

```
1. parser_v3.py → заменить DB подключение на db_wrapper
2. coordinator.py → заменить DB подключение на db_wrapper
3. Тест: запустить Москву (один город)
4. Тест: проверить данные в БД (nomenclature + prices)
5. db_wrapper.py → очистить несуществующие маппинги
6. (Опционально) Создать координационные таблицы для multi-city
7. Полный запуск: все 60 городов
8. Обновить DATABASE_ARCHITECTURE.md
```

### Ожидаемый результат

```
greenspark_nomenclature: ~15,000-25,000 товаров
greenspark_prices: ~100,000+ цен (60 городов × ~2,000 товаров)
```

GreenSpark станет 11-м работающим парсером → **11/11** на Homelab.
